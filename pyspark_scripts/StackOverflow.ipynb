{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:22:33.924923Z",
     "start_time": "2018-07-12T18:22:33.022Z"
    }
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "Question = collections.namedtuple(\"Question\", \"id id_user title text keywords views votes\")\n",
    "Answer = collections.namedtuple(\"Answer\", \"id id_question id_user text\")\n",
    "User = collections.namedtuple(\"User\", \"id reputation profile\")\n",
    "\n",
    "q1= Question (1,1,\"Cassandra Upsert not working on conditional writes\",\n",
    "              \"\"\"I made a conditional insert (if not exists) \\\\\\\n",
    "              statement using DataStax java driver but it doesn't work\"\"\",\n",
    "              \"Java Cassandra DataStax\", 1, 0)\n",
    "q2= Question (2,1,\"New Spark 2.2 Cassandra Connector\",\n",
    "              \"\"\" Tried to run the new connector to Spark 2.2 got error code 99129\n",
    "              who can be of help?\"\"\",\n",
    "              \"Spark Cassandra\", 2, 3)\n",
    "u1= User(1, 1, \"I'm an indipendent programmer, 8 years expertise in Java dev\");\n",
    "u2= User(2, 5, \"I'm Matei, Spark creator\");\n",
    "u3= User(3, 5, \"I'm Guido, Python benevolent dictator\");\n",
    "\n",
    "a1= Answer(1,1,2,\"I think there is still a problem in DataStax connector, try to use the one at this link XXX\")\n",
    "a2= Answer(2,2,2,\"Did you check server IP and Scala version?\")\n",
    "a3= Answer(3,2,3,\"I think you are using Python 2.7, while the new API is for Python 3.0\")\n",
    "questionsRDD=sc.parallelize([q1,q2])\n",
    "usersRDD=sc.parallelize([u1,u2,u3])\n",
    "answersRDD=sc.parallelize([a1,a2,a3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:23:03.325074Z",
     "start_time": "2018-07-12T18:23:00.215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Java', 'Cassandra', 'Spark', 'DataStax']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select questions keywords\n",
    "\n",
    "def get_keywords(s):\n",
    "    return s.split(\" \")\n",
    "\n",
    "\n",
    "keywordsRDD=questionsRDD.flatMap(lambda q: get_keywords(q.keywords)).distinct()\n",
    "\n",
    "keywordsRDD.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:25:17.792382Z",
     "start_time": "2018-07-12T18:25:17.319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, \"I'm Matei, Spark creator\"), (3, \"I'm Guido, Python benevolent dictator\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the power users, i.e., the users with the largest reputation providing also their profile\n",
    "max_reputation=usersRDD.map(lambda u: u.reputation).max()\n",
    "print(max_reputation)\n",
    "\n",
    "power_usersRDD=usersRDD.filter(lambda u: u.reputation==max_reputation).map(lambda u:(u.id,u.profile))\n",
    "power_usersRDD.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:25:43.077909Z",
     "start_time": "2018-07-12T18:25:42.215Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Answer(id=1, id_question=1, id_user=2, text='I think there is still a problem in DataStax connector, try to use the one at this link XXX'), Answer(id=2, id_question=2, id_user=2, text='Did you check server IP and Scala version?'), Answer(id=3, id_question=2, id_user=3, text='I think you are using Python 2.7, while the new API is for Python 3.0')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Select the keywords of the questions answered by the power users\n",
    "\n",
    "#Select power users' answers first\n",
    "power_users_ID=power_usersRDD.map(lambda u: u[0]).collect()\n",
    "power_answersRDD=answersRDD.filter(lambda a: a.id_user in power_users_ID)\n",
    "power_answersRDD.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:25:58.388498Z",
     "start_time": "2018-07-12T18:25:57.447Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "power_answersRDD_questions_IDs=power_answersRDD.map(lambda a: a.id_question).distinct().collect() \n",
    "print(power_answersRDD_questions_IDs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:26:33.672809Z",
     "start_time": "2018-07-12T18:26:33.136Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Java', 'Cassandra', 'Spark', 'DataStax']\n"
     ]
    }
   ],
   "source": [
    "print(questionsRDD.filter(lambda q: q.id in power_answersRDD_questions_IDs).\\\n",
    "flatMap(lambda q: get_keywords(q.keywords)).distinct().collect())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:27:37.296410Z",
     "start_time": "2018-07-12T18:27:36.377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Tried to run the new connector to Spark 2.2 got error code 99129\\n              who can be of help?', 'Did you check server IP and Scala version?'), (' Tried to run the new connector to Spark 2.2 got error code 99129\\n              who can be of help?', 'I think you are using Python 2.7, while the new API is for Python 3.0'), (\"I made a conditional insert (if not exists) \\\\              statement using DataStax java driver but it doesn't work\", 'I think there is still a problem in DataStax connector, try to use the one at this link XXX')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#provide questions and answers text\n",
    "questionsRDD.map(lambda q: (q.id, q.text)).\\\n",
    "join(answersRDD.map(lambda a: (a.id_question, a.text))).map(lambda x: x[1]).\\\n",
    "collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:27:51.789692Z",
     "start_time": "2018-07-12T18:27:50.956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (1, 1)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questionsRDD.join(answersRDD).map(lambda x: x[1]).collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:28:11.227726Z",
     "start_time": "2018-07-12T18:28:08.062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "questionsDF = questionsRDD.toDF([\"id\", \"id_user\", \"title\", \"text\", \"keywords\", \"views\", \"votes\"])\n",
    "usersDF = usersRDD.toDF([\"id\", \"reputation\", \"profile\"])\n",
    "answersDF = answersRDD.toDF([\"id\", \"id_question\", \"id_user\", \"text\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Select the power users, i.e., the users with the largest reputation providing also their profile\n",
    "max_reputation_2=usersDF.groupBy().max(\"reputation\").distinct().collect()[0][0]\n",
    "print(max_reputation_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:28:21.761071Z",
     "start_time": "2018-07-12T18:28:21.270Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=2, profile=\"I'm Matei, Spark creator\"), Row(id=3, profile=\"I'm Guido, Python benevolent dictator\")]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_usersDF=usersDF.filter(usersDF.reputation==max_reputation_2).select(\"id\",\"profile\")\n",
    "power_usersDF.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:28:42.064208Z",
     "start_time": "2018-07-12T18:28:41.530Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "#Select the keywords of the questions answered by the power users\n",
    "print(questionsDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:28:52.924084Z",
     "start_time": "2018-07-12T18:28:48.629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=3, id_question=2, id_user=3, text='I think you are using Python 2.7, while the new API is for Python 3.0', id=3, profile=\"I'm Guido, Python benevolent dictator\"), Row(id=1, id_question=1, id_user=2, text='I think there is still a problem in DataStax connector, try to use the one at this link XXX', id=2, profile=\"I'm Matei, Spark creator\"), Row(id=2, id_question=2, id_user=2, text='Did you check server IP and Scala version?', id=2, profile=\"I'm Matei, Spark creator\")]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_answersDF = answersDF.join(power_usersDF, answersDF.id_user == power_usersDF.id)\n",
    "\n",
    "power_answersDF.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:29:12.963216Z",
     "start_time": "2018-07-12T18:29:05.149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, id_user=1, title='Cassandra Upsert not working on conditional writes', text=\"I made a conditional insert (if not exists) \\\\              statement using DataStax java driver but it doesn't work\", keywords='Java Cassandra DataStax', views=1, votes=0, id_question=1, text='I think there is still a problem in DataStax connector, try to use the one at this link XXX'), Row(id=2, id_user=1, title='New Spark 2.2 Cassandra Connector', text=' Tried to run the new connector to Spark 2.2 got error code 99129\\n              who can be of help?', keywords='Spark Cassandra', views=2, votes=3, id_question=2, text='Did you check server IP and Scala version?'), Row(id=2, id_user=1, title='New Spark 2.2 Cassandra Connector', text=' Tried to run the new connector to Spark 2.2 got error code 99129\\n              who can be of help?', keywords='Spark Cassandra', views=2, votes=3, id_question=2, text='I think you are using Python 2.7, while the new API is for Python 3.0')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_answersDF_questions_IDs=power_answersDF.select(\"id_question\",\"text\").distinct()\n",
    "\n",
    "\n",
    "power_questions_answerDF = questionsDF.join(power_answersDF_questions_IDs,power_answersDF_questions_IDs.id_question==questionsDF.id)\n",
    "power_questions_answerDF.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-12T19:29:27.940317Z",
     "start_time": "2018-07-12T18:29:19.556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(keywords='Java Cassandra DataStax'), Row(keywords='Spark Cassandra')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power_questions_answerDF.select(\"keywords\").distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Toree - PySpark",
   "language": "python",
   "name": "toree_pyspark"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "pygments_lexer": "python",
   "version": "3.5.3\n"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
